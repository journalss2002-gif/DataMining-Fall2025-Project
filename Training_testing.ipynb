{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb8f250",
   "metadata": {},
   "source": [
    "Write Python code that loads a cleaned dataset, separates the features and target column ‘fraud’, performs a stratified train-test split (20% test size), and prints the shapes and fraud distribution in both training and testing sets. Keep it simple and readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5873451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (777336, 28)\n",
      "Original features: ['transaction_id', 'client_id', 'card_id', 'use_chip', 'merchant_id', 'mcc', 'fraud', 'has_chip', 'num_cards_issued', 'year_pin_last_changed', 'card_on_dark_web', 'current_age', 'gender', 'per_capita_income', 'num_credit_cards', 'account_age_days', 'account_age_years', 'card_brand_Discover', 'card_brand_Mastercard', 'card_brand_Visa', 'card_type_Debit', 'card_type_Debit (Prepaid)', 'outlier_iqr', 'amount_norm', 'credit_limit_norm', 'total_debt_norm', 'yearly_income_norm', 'credit_score_norm']\n",
      "\n",
      "Features containing '_id' to be removed: ['transaction_id', 'client_id', 'card_id', 'merchant_id']\n",
      "\n",
      "Updated dataset shape: (777336, 24)\n",
      "Updated features: ['use_chip', 'mcc', 'fraud', 'has_chip', 'num_cards_issued', 'year_pin_last_changed', 'card_on_dark_web', 'current_age', 'gender', 'per_capita_income', 'num_credit_cards', 'account_age_days', 'account_age_years', 'card_brand_Discover', 'card_brand_Mastercard', 'card_brand_Visa', 'card_type_Debit', 'card_type_Debit (Prepaid)', 'outlier_iqr', 'amount_norm', 'credit_limit_norm', 'total_debt_norm', 'yearly_income_norm', 'credit_score_norm']\n",
      "Total features removed: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# REMOVE ID FEATURES BEFORE LOADING DATASET\n",
    "# Features containing \"_id\" are typically identifiers (user_id, merchant_id, etc.)\n",
    "# These are not predictive and should be removed to avoid data leakage and noise\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df_labeled = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "\n",
    "print(f\"Original dataset shape: {df_labeled.shape}\")\n",
    "print(f\"Original features: {list(df_labeled.columns)}\")\n",
    "\n",
    "# Identify and remove features containing \"_id\"\n",
    "id_features = [col for col in df_labeled.columns if '_id' in col.lower()]\n",
    "print(f\"\\nFeatures containing '_id' to be removed: {id_features}\")\n",
    "\n",
    "# Remove _id features\n",
    "df_labeled = df_labeled.drop(columns=id_features)\n",
    "\n",
    "print(f\"\\nUpdated dataset shape: {df_labeled.shape}\")\n",
    "print(f\"Updated features: {list(df_labeled.columns)}\")\n",
    "print(f\"Total features removed: {len(id_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02b896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed ID features: ['transaction_id', 'client_id', 'card_id', 'merchant_id']\n",
      "Dataset shape after removing IDs: (777336, 24)\n",
      "Features used for training (23 total):\n",
      "  ['use_chip', 'mcc', 'has_chip', 'num_cards_issued', 'year_pin_last_changed', 'card_on_dark_web', 'current_age', 'gender', 'per_capita_income', 'num_credit_cards', 'account_age_days', 'account_age_years', 'card_brand_Discover', 'card_brand_Mastercard', 'card_brand_Visa', 'card_type_Debit', 'card_type_Debit (Prepaid)', 'outlier_iqr', 'amount_norm', 'credit_limit_norm', 'total_debt_norm', 'yearly_income_norm', 'credit_score_norm']\n",
      "Training shape: (621868, 23) (621868,)\n",
      "Testing shape: (155468, 23) (155468,)\n",
      "\n",
      "Training fraud distribution:\n",
      "fraud\n",
      "0    99.825043\n",
      "1     0.174957\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Testing fraud distribution:\n",
      "fraud\n",
      "0    99.825044\n",
      "1     0.174956\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 1. LOAD CLEANED DATASET\n",
    "# Load from the cleaned_dataset.csv (already processed and cleaned)\n",
    "df_labeled = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "\n",
    "# Remove ALL ID features (transaction_id, client_id, card_id, merchant_id)\n",
    "id_features = [col for col in df_labeled.columns if '_id' in col.lower()]\n",
    "df_labeled = df_labeled.drop(columns=id_features)\n",
    "print(f\"Removed ID features: {id_features}\")\n",
    "print(f\"Dataset shape after removing IDs: {df_labeled.shape}\")\n",
    "\n",
    "# 2. SEPARATE FEATURES (X) AND TARGET (y)\n",
    "# Drop the target label \"fraud\" to get only the input features.\n",
    "# `y` holds the binary fraud indicator (0 = legitimate, 1 = fraud).\n",
    "X = df_labeled.drop(columns=[\"fraud\"])\n",
    "y = df_labeled[\"fraud\"]\n",
    "\n",
    "print(f\"Features used for training ({X.shape[1]} total):\")\n",
    "print(f\"  {list(X.columns)}\")\n",
    "\n",
    "# 3. TRAIN–TEST SPLIT WITH STRATIFICATION\n",
    "\n",
    "# Splitting dataset into training (80%) and testing (20%).\n",
    "# `stratify=y` is CRITICAL for fraud datasets — ensures the fraud % stays\n",
    "# consistent across train and test sets despite imbalance.\n",
    "# `random_state=42` ensures reproducibility of the split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,          # 20% test size for evaluation\n",
    "    random_state=42,        # reproducible results\n",
    "    stratify=y              # preserves fraud ratio!\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 4. INSPECT SPLIT SHAPES + DISTRIBUTION\n",
    "\n",
    "# Confirms correct partition sizes and checks that stratification worked.\n",
    "print(\"Training shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "print(\"\\nTraining fraud distribution:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)   # % of fraud vs non-fraud\n",
    "\n",
    "print(\"\\nTesting fraud distribution:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)    # should match training %\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561b4a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\journ\\onedrive\\desktop\\cosc463_project\\venv\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\journ\\onedrive\\desktop\\cosc463_project\\venv\\lib\\site-packages (from imbalanced-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\journ\\onedrive\\desktop\\cosc463_project\\venv\\lib\\site-packages (from imbalanced-learn) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\journ\\onedrive\\desktop\\cosc463_project\\venv\\lib\\site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\journ\\onedrive\\desktop\\cosc463_project\\venv\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\journ\\onedrive\\desktop\\cosc463_project\\venv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e63cb4",
   "metadata": {},
   "source": [
    "Write Python code that applies SMOTE to handle class imbalance in the fraud dataset.Use a sampling strategy of 0.1, apply it only on the training set to avoid data leakage, and print the class distribution before and after SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101ac47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before SMOTE: fraud\n",
      "0    620780\n",
      "1      1088\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After SMOTE: fraud\n",
      "0    620780\n",
      "1     62078\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# APPLY SMOTE TO FIX EXTREME IMBALANCE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE generates synthetic minority-class samples (fraud cases)\n",
    "# This helps the model learn fraud patterns instead of being overwhelmed by majority class.\n",
    "# sampling_strategy=0.1 → minority class becomes 10% of the training data\n",
    "# This is intentionally NOT 50/50 to avoid unrealistic inflation + overfitting.\n",
    "sm = SMOTE(sampling_strategy=0.1, random_state=42)\n",
    "\n",
    "# IMPORTANT:\n",
    "# Fit SMOTE **ONLY on the training set**.\n",
    "# Applying it to the test set would leak synthetic patterns → invalid evaluation!\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Compare original vs resampled class distribution\n",
    "print(\"\\nBefore SMOTE:\", y_train.value_counts())\n",
    "print(\"\\nAfter SMOTE:\", y_train_res.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66b642",
   "metadata": {},
   "source": [
    "Write Python code that trains a Logistic Regression and a Decision Tree for fraud detection.\n",
    "Both models should use class_weight='balanced' to handle imbalance, and they should be trained on the SMOTE-resampled data.\n",
    "Add clear comments explaining why class weighting matters and why each model is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef67a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Complete: Logistic Regression + Decision Tree\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1) LOGISTIC REGRESSION (WITH CLASS WEIGHTING)\n",
    "# class_weight=\"balanced\" forces LR to scale the importance of fraud cases.\n",
    "# Without this, LR would ignore minority class completely due to extreme imbalance.\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight=\"balanced\",   # adjust weights inversely proportional to class frequency\n",
    "    max_iter=2000,              # increases iterations so model fully converges\n",
    "    n_jobs=-1                  # use all CPU cores for faster training\n",
    ")\n",
    "\n",
    "# 2) DECISION TREE CLASSIFIER\n",
    "# Decision Trees capture nonlinear fraud patterns (e.g., amount thresholds, MCC behavior).\n",
    "# class_weight=\"balanced\" again prevents bias toward the majority class.\n",
    "tree_clf = DecisionTreeClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42            \n",
    ")\n",
    "\n",
    "\n",
    "# TRAIN BOTH MODELS ON SMOTE-RESAMPLED DATA\n",
    "# We use X_train_res / y_train_res to ensure both models learn from a balanced structure.\n",
    "# SMOTE helps both linear (LR) and nonlinear (Tree) models better identify fraud signals.\n",
    "log_reg.fit(X_train_res, y_train_res)\n",
    "tree_clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Model Training Complete: Logistic Regression + Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f10cb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated predictions on the true test set.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PREDICT ON ORIGINAL TEST SET (NO SMOTE HERE)\n",
    "\n",
    "# Logistic Regression predictions\n",
    "y_prob_log = log_reg.predict_proba(X_test)[:, 1]\n",
    "y_pred_log = (y_prob_log >= 0.5).astype(int)\n",
    "\n",
    "# Decision Tree predictions\n",
    "y_prob_tree = tree_clf.predict_proba(X_test)[:, 1]\n",
    "y_pred_tree = (y_prob_tree >= 0.5).astype(int)\n",
    "\n",
    "print(\"Generated predictions on the true test set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e59ca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Logistic Regression Cross-Validation Results -----\n",
      "Precision (mean ± std): 0.1986 ± 0.0017\n",
      "Recall (mean ± std): 0.6129 ± 0.0039\n",
      "F1 (mean ± std): 0.2999 ± 0.0015\n",
      "Roc_auc (mean ± std): 0.7572 ± 0.0014\n",
      "\n",
      "----- Decision Tree Cross-Validation Results -----\n",
      "Precision (mean ± std): 0.9738 ± 0.0012\n",
      "Recall (mean ± std): 0.9735 ± 0.0011\n",
      "F1 (mean ± std): 0.9736 ± 0.0008\n",
      "Roc_auc (mean ± std): 0.9854 ± 0.0005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#CROSS-VALIDATION FOR BOTH MODELS\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "# StratifiedKFold ensures each fold keeps the same fraud ratio.\n",
    "# This is CRITICAL for fraud modeling—regular KFold would randomly break the imbalance pattern.\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,         # 5-fold CV = standard, stable\n",
    "    shuffle=True,       # shuffle ensures better randomness across folds\n",
    "    random_state=42     # reproducibility\n",
    ")\n",
    "\n",
    "# Metrics to evaluate across all folds.\n",
    "# We focus on precision, recall, F1, and ROC-AUC — the most important in fraud detection.\n",
    "scoring = {\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\",\n",
    "    \"roc_auc\": \"roc_auc\"\n",
    "}\n",
    "\n",
    "# CROSS-VALIDATION — LOGISTIC REGRESSION\n",
    "\n",
    "log_cv = cross_validate(\n",
    "    log_reg,\n",
    "    X_train_res,        # SMOTE-resampled training data\n",
    "    y_train_res,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1           # use all CPU cores\n",
    ")\n",
    "\n",
    "\n",
    "# CROSS-VALIDATION — DECISION TREE\n",
    "\n",
    "tree_cv = cross_validate(\n",
    "    tree_clf,\n",
    "    X_train_res,\n",
    "    y_train_res,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# DISPLAY CROSS-VALIDATION RESULTS \n",
    "\n",
    "def show_cv_results(name, cv_results):\n",
    "    print(f\"\\n----- {name} Cross-Validation Results -----\")\n",
    "    # Loop through each metric and display mean ± standard deviation across folds.\n",
    "    for metric in scoring.keys():\n",
    "        scores = cv_results[f\"test_{metric}\"]\n",
    "        print(f\"{metric.capitalize()} (mean ± std): {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "show_cv_results(\"Logistic Regression\", log_cv)\n",
    "show_cv_results(\"Decision Tree\", tree_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b81547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Logistic Regression =================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[116959  38237]\n",
      " [   174     98]]\n",
      "TN=116959, FP=38237, FN=174, TP=98\n",
      "\n",
      "Performance Summary:\n",
      "      Metric     Value\n",
      "0   Accuracy  0.752933\n",
      "1  Precision  0.002556\n",
      "2     Recall  0.360294\n",
      "3   F1 Score  0.005077\n",
      "4    ROC-AUC  0.588170\n",
      "5     PR-AUC  0.002365\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9985    0.7536    0.8590    155196\n",
      "           1     0.0026    0.3603    0.0051       272\n",
      "\n",
      "    accuracy                         0.7529    155468\n",
      "   macro avg     0.5005    0.5570    0.4320    155468\n",
      "weighted avg     0.9968    0.7529    0.8575    155468\n",
      "\n",
      "\n",
      "================ Decision Tree =================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[154836    360]\n",
      " [   201     71]]\n",
      "TN=154836, FP=360, FN=201, TP=71\n",
      "\n",
      "Performance Summary:\n",
      "      Metric     Value\n",
      "0   Accuracy  0.996392\n",
      "1  Precision  0.164733\n",
      "2     Recall  0.261029\n",
      "3   F1 Score  0.201991\n",
      "4    ROC-AUC  0.629355\n",
      "5     PR-AUC  0.213528\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9987    0.9977    0.9982    155196\n",
      "           1     0.1647    0.2610    0.2020       272\n",
      "\n",
      "    accuracy                         0.9964    155468\n",
      "   macro avg     0.5817    0.6294    0.6001    155468\n",
      "weighted avg     0.9972    0.9964    0.9968    155468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve, roc_auc_score, auc,\n",
    "    precision_score, recall_score, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "def evaluate_model(name, y_test, y_pred, y_prob):\n",
    "    print(f\"\\n================ {name} =================\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    pr_precision, pr_recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    pr_auc = auc(pr_recall, pr_precision)\n",
    "\n",
    "    # Table\n",
    "    results_table = pd.DataFrame({\n",
    "        \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC-AUC\", \"PR-AUC\"],\n",
    "        \"Value\": [accuracy, precision, recall, f1, roc, pr_auc]\n",
    "    })\n",
    "\n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(results_table)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# ---- CALL THE FUNCTION ----\n",
    "evaluate_model(\"Logistic Regression\", y_test, y_pred_log, y_prob_log)\n",
    "evaluate_model(\"Decision Tree\", y_test, y_pred_tree, y_prob_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9511fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DECISION TREE DETAILED PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[154836    360]\n",
      " [   201     71]]\n",
      "\n",
      "Breakdown:\n",
      "  True Negatives (TN):  154,836  — Correctly identified legitimate transactions\n",
      "  False Positives (FP): 360  — Legitimate flagged as fraud (false alarms)\n",
      "  False Negatives (FN): 201  — Fraud missed as legitimate (misses)\n",
      "  True Positives (TP):  71  — Correctly identified fraud cases\n",
      "\n",
      "Performance Summary:\n",
      "   Metric    Value\n",
      " Accuracy 0.996392\n",
      "Precision 0.164733\n",
      "   Recall 0.261029\n",
      " F1 Score 0.201991\n",
      "  ROC-AUC 0.629355\n",
      "   PR-AUC 0.213528\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9987    0.9977    0.9982    155196\n",
      "           1     0.1647    0.2610    0.2020       272\n",
      "\n",
      "    accuracy                         0.9964    155468\n",
      "   macro avg     0.5817    0.6294    0.6001    155468\n",
      "weighted avg     0.9972    0.9964    0.9968    155468\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "KEY INSIGHTS FOR DECISION TREE:\n",
      "--------------------------------------------------------------------------------\n",
      "Precision: 0.1647 (16.47%)\n",
      "  → Of 431 transactions flagged as fraud, 71 were actually fraud\n",
      "  → 83.53% are false alarms\n",
      "\n",
      "Recall: 0.2610 (26.10%)\n",
      "  → Of 272 actual fraud cases, 71 were caught\n",
      "  → 73.90% of fraud slipped through undetected\n",
      "\n",
      "F1 Score: 0.2020\n",
      "  → Balances precision (0.1647) and recall (0.2610)\n",
      "\n",
      "ROC-AUC: 0.6294\n",
      "  → Model discrimination ability (0.5 = random, 1.0 = perfect)\n",
      "\n",
      "PR-AUC: 0.2135\n",
      "  → Precision-Recall area (best metric for imbalanced fraud data)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DETAILED DECISION TREE EVALUATION (FORMATTED OUTPUT)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve, roc_auc_score, auc,\n",
    "    precision_score, recall_score, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DECISION TREE DETAILED PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Confusion Matrix breakdown\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "tn_tree, fp_tree, fn_tree, tp_tree = cm_tree.ravel()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_tree)\n",
    "print(f\"\\nBreakdown:\")\n",
    "print(f\"  True Negatives (TN):  {tn_tree:,}  — Correctly identified legitimate transactions\")\n",
    "print(f\"  False Positives (FP): {fp_tree:,}  — Legitimate flagged as fraud (false alarms)\")\n",
    "print(f\"  False Negatives (FN): {fn_tree:,}  — Fraud missed as legitimate (misses)\")\n",
    "print(f\"  True Positives (TP):  {tp_tree:,}  — Correctly identified fraud cases\")\n",
    "\n",
    "# Calculate metrics\n",
    "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
    "prec_tree = precision_score(y_test, y_pred_tree, zero_division=0)\n",
    "rec_tree = recall_score(y_test, y_pred_tree, zero_division=0)\n",
    "f1_tree = f1_score(y_test, y_pred_tree, zero_division=0)\n",
    "roc_tree = roc_auc_score(y_test, y_prob_tree)\n",
    "\n",
    "pr_prec_tree, pr_rec_tree, _ = precision_recall_curve(y_test, y_prob_tree)\n",
    "pr_auc_tree = auc(pr_rec_tree, pr_prec_tree)\n",
    "\n",
    "# Performance Summary Table\n",
    "results_table_tree = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC-AUC\", \"PR-AUC\"],\n",
    "    \"Value\": [acc_tree, prec_tree, rec_tree, f1_tree, roc_tree, pr_auc_tree]\n",
    "})\n",
    "\n",
    "print(\"\\nPerformance Summary:\")\n",
    "print(results_table_tree.to_string(index=False))\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_tree, digits=4))\n",
    "\n",
    "# Comparison summary\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"KEY INSIGHTS FOR DECISION TREE:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Precision: {prec_tree:.4f} ({prec_tree*100:.2f}%)\")\n",
    "print(f\"  → Of {tp_tree + fp_tree:,} transactions flagged as fraud, {tp_tree} were actually fraud\")\n",
    "print(f\"  → {(1-prec_tree)*100:.2f}% are false alarms\")\n",
    "print(f\"\\nRecall: {rec_tree:.4f} ({rec_tree*100:.2f}%)\")\n",
    "print(f\"  → Of {tp_tree + fn_tree} actual fraud cases, {tp_tree} were caught\")\n",
    "print(f\"  → {(1-rec_tree)*100:.2f}% of fraud slipped through undetected\")\n",
    "print(f\"\\nF1 Score: {f1_tree:.4f}\")\n",
    "print(f\"  → Balances precision ({prec_tree:.4f}) and recall ({rec_tree:.4f})\")\n",
    "print(f\"\\nROC-AUC: {roc_tree:.4f}\")\n",
    "print(f\"  → Model discrimination ability (0.5 = random, 1.0 = perfect)\")\n",
    "print(f\"\\nPR-AUC: {pr_auc_tree:.4f}\")\n",
    "print(f\"  → Precision-Recall area (best metric for imbalanced fraud data)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
